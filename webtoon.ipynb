{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of           id              title      author      genre  \\\n",
       "0     756056       가난을 등에 업은 소녀  B급달궁 / 오은지   스토리, 로맨스   \n",
       "1     670144               가담항설          랑또   스토리, 판타지   \n",
       "2     732071       가령의 정체불명 이야기          가령  옴니버스, 드라마   \n",
       "3     703844              가비지타임         2사장   스토리, 스포츠   \n",
       "4     785701             가상&RPG         주다현   스토리, 판타지   \n",
       "...      ...                ...         ...        ...   \n",
       "2095  675393    [드라마원작] 한번 더 해요     미티 / 구구   스토리, 드라마   \n",
       "2096  687921    [드라마원작] 아일랜드 2부   윤인완 / 양경일   스토리, 스릴러   \n",
       "2097  677536  [드라마원작] 내 ID는 ...         기맹기   스토리, 로맨스   \n",
       "2098  678500    [드라마원작] 아일랜드 1부   윤인완 / 양경일   스토리, 스릴러   \n",
       "2099   67235  [드라마원작] 지금 우리 ...         주동근   스토리, 스릴러   \n",
       "\n",
       "                                            description  rating  \\\n",
       "0     흔하디 흔한 재벌후계자와 캔디도 울고 갈 박복한 가난소녀의 파란만장 동거기!인기작 ...    9.13   \n",
       "1     이번 주인공은 돌이다!돌이지만 동료도 모으고 악당도 물리친다!랑또 작가표 동양 판타...    9.98   \n",
       "2     어느 날... 인어가 내게 말을 걸어왔다. 눈을 떠보니 총구가 있었다. 그리고 몸이...    9.95   \n",
       "3       한국 최초 한국형 고교스포츠 웹툰!열혈따윈 개나 줘, 낙오자들 뿐인 농구부의 운명은?    9.96   \n",
       "4     \"사람은 좀 죽여도 싸우는건 싫어해요.\" 게임에서조차 집 바깥을 나가지 않는 '제리...    9.91   \n",
       "...                                                 ...     ...   \n",
       "2095  결혼 8년차 부부. 성대광과 유선영. 대학시절 킹카 퀸카로 CC로 만나 결혼까지 골...    9.91   \n",
       "2096  악귀들이 가득찬 섬 제주도. 이를 물리치는 토막살인범 반. 웹툰으로 새롭게 돌아온 ...    9.97   \n",
       "2097  못생긴 얼굴에서 미인으로 새롭게 태어난 그녀, 강미래! 그런데... 어디서 본 듯 한데?    9.83   \n",
       "2098  악귀들이 가득찬 섬 제주도. 이를 물리치는 토막살인범 반. 웹툰으로 돌아온 퇴마만화...    9.96   \n",
       "2099  평범하던 학교에 벌어진 감금사건..그리고 감금사건에 가려 미처 알지 못한 감염자. ...    9.56   \n",
       "\n",
       "                  date  completed      age   free  \\\n",
       "0     2020.10.19 00:00       True    전체연령가   True   \n",
       "1     2020.10.07 23:00       True  12세 이용가   True   \n",
       "2     2020.02.03 23:22       True  15세 이용가   True   \n",
       "3     2022.12.24 22:57      False    전체연령가  False   \n",
       "4     2022.10.19 23:00      False  12세 이용가  False   \n",
       "...                ...        ...      ...    ...   \n",
       "2095        2018.03.22       True  18세 이용가   True   \n",
       "2096        2018.02.14       True  15세 이용가   True   \n",
       "2097        2017.12.29       True  12세 이용가   True   \n",
       "2098        2016.10.20       True  15세 이용가   True   \n",
       "2099        2011.11.09       True  18세 이용가   True   \n",
       "\n",
       "                                                   link  \n",
       "0     https://comic.naver.com/webtoon/list?titleId=7...  \n",
       "1     https://comic.naver.com/webtoon/list?titleId=6...  \n",
       "2     https://comic.naver.com/webtoon/list?titleId=7...  \n",
       "3     https://comic.naver.com/webtoon/list?titleId=7...  \n",
       "4     https://comic.naver.com/webtoon/list?titleId=7...  \n",
       "...                                                 ...  \n",
       "2095  https://comic.naver.com/webtoon/list?titleId=6...  \n",
       "2096  https://comic.naver.com/webtoon/list?titleId=6...  \n",
       "2097  https://comic.naver.com/webtoon/list?titleId=6...  \n",
       "2098  https://comic.naver.com/webtoon/list?titleId=6...  \n",
       "2099  https://comic.naver.com/webtoon/list?titleId=6...  \n",
       "\n",
       "[2100 rows x 11 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtoon=pd.read_csv('webtoon.csv')\n",
    "toon = pd.DataFrame(webtoon)\n",
    "toon.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    흔하디 흔한 재벌후계자와 캔디도 울고 갈 박복한 가난소녀의 파란만장 동거기!인기작 ...\n",
      "1    이번 주인공은 돌이다!돌이지만 동료도 모으고 악당도 물리친다!랑또 작가표 동양 판타...\n",
      "2    어느 날... 인어가 내게 말을 걸어왔다. 눈을 떠보니 총구가 있었다. 그리고 몸이...\n",
      "3      한국 최초 한국형 고교스포츠 웹툰!열혈따윈 개나 줘, 낙오자들 뿐인 농구부의 운명은?\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "desc = toon['description']\n",
    "print(desc[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "흔하디 흔한 재벌후계자와 캔디도 울고 갈 박복한 가난소녀의 파란만장 동거기인기작 다세포소녀의 웹툰판\n"
     ]
    }
   ],
   "source": [
    "text=re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\",\"\",desc[0])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['하디', '재벌', '후계', '캔디', '울', '가난', '소녀', '파란만장', '동거', '인기', '작', '다세포', '소녀', '웹툰', '판']\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "review_text=okt.nouns(text)\n",
    "print(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, okt, remove_stopwords = False, stop_words = []):\n",
    "    # text : 전처리할 텍스트\n",
    "    # okt : okt 객체를 반복적으로 생성하지 않고 미리 생성후 인자로 받는다.\n",
    "    \n",
    "    # 1. 한글 및 공백을 제외한 문자 모두 제거.\n",
    "    desc_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", text)\n",
    "    \n",
    "    # 2. okt 객체를 활용해서 형태소 단위로 나눈다.\n",
    "    word_desc = okt.nouns(desc_text)\n",
    "\n",
    "    return word_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_desc=[]\n",
    "stop_words=set(['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한','그'])\n",
    "for desc in toon['description']:\n",
    "    # 빈 데이터에서 멈추지 않도록 문자열인 경우에만 진행\n",
    "    if type(desc)==str:\n",
    "        clean_desc.append(preprocessing(desc, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        # stirng이 아니면 비어있는 값 추가\n",
    "        clean_desc.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['하디', '재벌', '후계', '캔디', '울', '가난', '소녀', '파란만장', '동거', '인기', '작', '다세포', '소녀', '웹툰', '판'], ['이번', '주인공', '돌이', '돌이', '동료', '악당', '물리', '또', '가표', '동양', '판타지', '소년만화'], ['날', '인어', '말', '눈', '총구', '몸', '연기', '시작', '판타지', '비현실적', '우리', '회색', '빛', '이야기'], ['한국', '최초', '한국', '고교', '스포츠', '웹툰', '혈', '윈', '개', '낙', '오자', '농구부', '운명'], ['사람', '좀', '게임', '집', '바깥', '제리', '전투', '번', '에픽', '무기', '귀속', '가상현실', '액션', '모브사', '온라인', '그', '인물', '군상']]\n"
     ]
    }
   ],
   "source": [
    "print(clean_desc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.339615384615385\n"
     ]
    }
   ],
   "source": [
    "num_lists = len(clean_desc)\n",
    "num_elements = sum(len(inner_list) for inner_list in clean_desc)\n",
    "# 토큰의 평균 갯수\n",
    "average = num_elements / num_lists\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챌린지 웹툰을 테스트 데이터로 사용\n",
    "chal_webtoon=pd.read_csv('webtoon_challenge.csv')\n",
    "chal_toon = pd.DataFrame(chal_webtoon)\n",
    "\n",
    "clean_chal_desc=[]\n",
    "stop_words=set(['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한','그'])\n",
    "for desc in chal_toon['description'][:500]:\n",
    "    # 빈 데이터에서 멈추지 않도록 문자열인 경우에만 진행\n",
    "    if type(desc)==str:\n",
    "        clean_chal_desc.append(preprocessing(desc, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        # stirng이 아니면 비어있는 값 추가\n",
    "        clean_chal_desc.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_desc)\n",
    "train_sequences=tokenizer.texts_to_sequences(clean_desc)\n",
    "test_sequences=tokenizer.texts_to_sequences(clean_chal_desc)\n",
    "\n",
    "# 단어 사전 형태\n",
    "word_vocab=tokenizer.word_index\n",
    "\n",
    "# 문장 최대 길이\n",
    "MAX_SEQUENCE_LENGTH=19\n",
    "\n",
    "# 학습 데이터를 벡터화\n",
    "train_inputs=pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "# 학습 데이터의 라벨\n",
    "train_labels=np.array([toon['rating']])\n",
    "\n",
    "# 평가 데이터를 벡터화\n",
    "test_inputs=pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "# 평가 데이터의 라벨\n",
    "test_labels=np.array(chal_toon['rating'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.reshape(-1,)\n",
    "test_labels = test_labels.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_labels[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_labels = scaler.fit_transform(toon['rating'].values.reshape(-1,1))\n",
    "test_labels = scaler.transform(chal_toon['rating'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8679\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4457  277  682 4458  556 1740   35 1235  243  114  258 4459   35   56\n",
      "   824    0    0    0    0]\n",
      " [ 244   41 1072 1072  428  598  933  111 4460 2951   52 4461    0    0\n",
      "     0    0    0    0    0]\n",
      " [   9 2188   66   40 4462   71  391    3   52 4463   49 2189  392    6\n",
      "     0    0    0    0    0]\n",
      " [ 174  683  174  825  599   56 1073 4464  278 4465 2952 2953   61    0\n",
      "     0    0    0    0    0]\n",
      " [   5  517   31   50 2954 4466  934  124 4467  935 2955 1741   94 4468\n",
      "  1074    1  318 2956    0]\n",
      " [  88 1742   28  207  936 4469   29 4470 1743  485 1743 4471 1743  334\n",
      "    38    0    0    0    0]\n",
      " [2957 2190  486  752 4472 4473  346    6 4474   11  203  450   38    0\n",
      "     0    0    0    0    0]\n",
      " [4475   21   99 4476   50  243    3 1744   85  294   12    3   82   13\n",
      "    82   13  367  107   82]\n",
      " [ 231   77  826   82  827   86   82    6    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 19)\n",
      "(2100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 하이퍼 파라미터\n",
    "EMB_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "input_train, input_eval, label_train, label_eval=train_test_split(train_inputs, train_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 19) (3192, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_inputs.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 3s 19ms/step - loss: 1.0326 - mean_absolute_error: 0.4785 - val_loss: 0.7435 - val_mean_absolute_error: 0.4563\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6321 - mean_absolute_error: 0.4042\n",
      "Test Mean Absolute Error: 0.40415874123573303\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_vocab) + 1, EMB_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(LSTM(EMB_SIZE))\n",
    "model.add(Dense(1))  # No activation function for regression\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train model\n",
    "model.fit(train_inputs, train_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1)\n",
    "loss, mae = model.evaluate(test_inputs, test_labels)\n",
    "print(f'Test Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.826\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(test_inputs)\n",
    "\n",
    "# Compute custom accuracy\n",
    "accuracy = np.mean(np.abs(predictions - test_labels) < 0.5)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
